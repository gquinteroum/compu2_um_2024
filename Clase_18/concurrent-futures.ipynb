{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](images/um_logo.png)\n",
    "\n",
    "# Computación II: Concurrent Futures en Python\n",
    "\n",
    "## Introducción a concurrent.futures\n",
    "\n",
    "El módulo `concurrent.futures` es una parte poderosa de la biblioteca estándar de Python que proporciona una interfaz de alto nivel para trabajar con tareas concurrentes y paralelas. Este módulo es esencial para desarrolladores que buscan mejorar el rendimiento de sus aplicaciones aprovechando la concurrencia y el paralelismo.\n",
    "\n",
    "### ¿Por qué usar concurrent.futures?\n",
    "\n",
    "1. **Simplicidad**: Ofrece una API fácil de usar para la programación concurrente.\n",
    "2. **Flexibilidad**: Permite cambiar fácilmente entre ejecución en hilos y procesos.\n",
    "3. **Control**: Proporciona herramientas para manejar el estado y los resultados de las tareas.\n",
    "4. **Escalabilidad**: Facilita la distribución de trabajo en múltiples núcleos de CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivación y Razón de Ser de concurrent.futures\n",
    "\n",
    "El módulo `concurrent.futures` fue introducido en Python 3.2 como parte de la PEP 3148. Su principal objetivo es proporcionar una interfaz de alto nivel para la ejecución asíncrona de llamadas a funciones. Este módulo surge de la necesidad de simplificar y unificar la programación concurrente en Python, ofreciendo varias ventajas sobre el uso directo de `threading` y `multiprocessing`:\n",
    "\n",
    "1. **Interfaz unificada**: `concurrent.futures` proporciona una API consistente para trabajar tanto con hilos (`ThreadPoolExecutor`) como con procesos (`ProcessPoolExecutor`). Esto permite cambiar fácilmente entre ejecución basada en hilos y procesos sin modificar significativamente el código.\n",
    "\n",
    "2. **Abstracción de alto nivel**: A diferencia de `threading` y `multiprocessing`, que requieren una gestión manual de hilos y procesos, `concurrent.futures` abstrae estos detalles, permitiendo al programador centrarse en la lógica de la aplicación.\n",
    "\n",
    "3. **Manejo simplificado de resultados**: El uso de objetos `Future` facilita la obtención de resultados de tareas asíncronas, proporcionando métodos para verificar el estado de las tareas y recuperar sus resultados.\n",
    "\n",
    "4. **Pool de workers gestionado**: El módulo gestiona automáticamente un pool de workers (hilos o procesos), eliminando la necesidad de crear y gestionar manualmente estos recursos.\n",
    "\n",
    "5. **Compatibilidad con contextos**: El uso de administradores de contexto (`with` statement) simplifica la gestión del ciclo de vida de los executors.\n",
    "\n",
    "6. **Cancelación de tareas**: Ofrece mecanismos para cancelar tareas que aún no han comenzado a ejecutarse, una característica no fácilmente disponible en `threading` o `multiprocessing`.\n",
    "\n",
    "Comparación con `threading` y `multiprocessing`:\n",
    "\n",
    "- **Nivel de abstracción**: `concurrent.futures` opera a un nivel más alto, ocultando muchos de los detalles de implementación que `threading` y `multiprocessing` exponen.\n",
    "- **Facilidad de uso**: Requiere menos código boilerplate (secciones de código que deben incluirse en muchos lugares con poca o ninguna alteración) y manejo manual de sincronización en comparación con `threading` y `multiprocessing`.\n",
    "- **Flexibilidad**: Permite cambiar fácilmente entre ejecución basada en hilos y procesos, lo cual no es trivial cuando se usa directamente `threading` o `multiprocessing`.\n",
    "- **Limitaciones**: Aunque es más fácil de usar, `concurrent.futures` puede ser menos flexible para escenarios muy específicos o complejos donde se necesita un control fino sobre hilos o procesos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conceptos Clave\n",
    "\n",
    "### 1. Executor\n",
    "Es la base de `concurrent.futures`. Hay dos tipos principales:\n",
    "- `ThreadPoolExecutor`: Para tareas limitadas por I/O.\n",
    "- `ProcessPoolExecutor`: Para tareas limitadas por CPU.\n",
    "\n",
    "### 2. Future\n",
    "Representa el resultado pendiente de una operación asíncrona.\n",
    "\n",
    "### 3. Pool\n",
    "Un conjunto de workers (hilos o procesos) que ejecutan tareas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Tareas CPU-bound vs I/O-bound\n",
    "\n",
    "#### Tareas CPU-bound\n",
    "Las tareas CPU-bound son aquellas que pasan la mayor parte del tiempo realizando cálculos en la CPU. Estas tareas están limitadas por la velocidad de procesamiento de la CPU.\n",
    "\n",
    "Características de las tareas CPU-bound:\n",
    "- Realizan cálculos intensivos\n",
    "- No pasan mucho tiempo esperando por operaciones de entrada/salida\n",
    "- Pueden beneficiarse significativamente del procesamiento paralelo en múltiples núcleos\n",
    "\n",
    "Ejemplos de tareas CPU-bound:\n",
    "- Cálculos matemáticos complejos\n",
    "- Procesamiento de imágenes o video\n",
    "- Simulaciones científicas\n",
    "- Algoritmos de machine learning\n",
    "\n",
    "Para tareas CPU-bound, `ProcessPoolExecutor` es generalmente más eficiente debido a que puede aprovechar múltiples núcleos de CPU.\n",
    "\n",
    "#### Tareas I/O-bound\n",
    "En contraste, las tareas I/O-bound pasan la mayor parte del tiempo esperando por operaciones de entrada/salida, como lecturas de disco, solicitudes de red, o interacciones con bases de datos.\n",
    "\n",
    "Características de las tareas I/O-bound:\n",
    "- Pasan mucho tiempo esperando por operaciones de E/S\n",
    "- No realizan cálculos intensivos\n",
    "- Pueden beneficiarse de la concurrencia, incluso en un solo núcleo\n",
    "\n",
    "Ejemplos de tareas I/O-bound:\n",
    "- Solicitudes a APIs web\n",
    "- Operaciones de lectura/escritura en archivos\n",
    "- Consultas a bases de datos\n",
    "- Descarga de archivos\n",
    "\n",
    "Para tareas I/O-bound, `ThreadPoolExecutor` es generalmente más eficiente debido a su menor overhead y capacidad para manejar múltiples operaciones de E/S concurrentemente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ThreadPoolExecutor vs ProcessPoolExecutor\n",
    "\n",
    "| Característica | ThreadPoolExecutor | ProcessPoolExecutor |\n",
    "|----------------|---------------------|----------------------|\n",
    "| Uso ideal      | Tareas I/O bound    | Tareas CPU bound     |\n",
    "| Overhead       | Bajo                | Alto                 |\n",
    "| GIL            | Compartido          | Separado por proceso |\n",
    "| Memoria        | Compartida          | Separada             |\n",
    "| Comunicación   | Rápida              | Más lenta            |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplos Prácticos\n",
    "\n",
    "### 1. Uso básico de ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import time\n",
    "\n",
    "def worker(name):\n",
    "    print(f\"Worker {name} iniciando...\")\n",
    "    time.sleep(2)  # Simulamos una tarea que toma tiempo\n",
    "    return f\"Worker {name} terminó\"\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "    futures = [executor.submit(worker, f\"A{i}\") for i in range(5)]\n",
    "    \n",
    "    for future in futures:\n",
    "        print(future.result())\n",
    "\n",
    "print(\"Todas las tareas completadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Uso de ProcessPoolExecutor para tareas CPU-bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import math\n",
    "\n",
    "def es_primo(n):\n",
    "    if n < 2:\n",
    "        return False\n",
    "    for i in range(2, int(math.sqrt(n)) + 1):\n",
    "        if n % i == 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "numeros = range(1, 100000, 1000)\n",
    "\n",
    "with ProcessPoolExecutor() as executor:\n",
    "    resultados = executor.map(es_primo, numeros)\n",
    "\n",
    "primos = [num for num, es_primo in zip(numeros, resultados) if es_primo]\n",
    "print(f\"Números primos encontrados: {primos}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Comparación de rendimiento\n",
    "\n",
    "Vamos a comparar el rendimiento de ejecución secuencial, ThreadPoolExecutor y ProcessPoolExecutor para una tarea CPU-bound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
    "\n",
    "def tarea_intensiva(n):\n",
    "    return sum(i * i for i in range(n))\n",
    "\n",
    "def ejecutar_secuencial(nums):\n",
    "    return [tarea_intensiva(num) for num in nums]\n",
    "\n",
    "def ejecutar_con_threads(nums):\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        return list(executor.map(tarea_intensiva, nums))\n",
    "\n",
    "def ejecutar_con_procesos(nums):\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        return list(executor.map(tarea_intensiva, nums))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    numeros = [10**6, 10**6, 10**6, 10**6]  # Ajusta según tu CPU\n",
    "    \n",
    "    inicio = time.time()\n",
    "    ejecutar_secuencial(numeros)\n",
    "    tiempo_secuencial = time.time() - inicio\n",
    "    \n",
    "    inicio = time.time()\n",
    "    ejecutar_con_threads(numeros)\n",
    "    tiempo_threads = time.time() - inicio\n",
    "    \n",
    "    inicio = time.time()\n",
    "    ejecutar_con_procesos(numeros)\n",
    "    tiempo_procesos = time.time() - inicio\n",
    "    \n",
    "    print(f\"Tiempo secuencial: {tiempo_secuencial:.2f} segundos\")\n",
    "    print(f\"Tiempo con threads: {tiempo_threads:.2f} segundos\")\n",
    "    print(f\"Tiempo con procesos: {tiempo_procesos:.2f} segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Comparación rápida de código boilerplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con threading (más boilerplate)\n",
    "import threading\n",
    "\n",
    "def worker(num):\n",
    "    print(f\"Tarea {num} completada\")\n",
    "\n",
    "threads = []\n",
    "for i in range(5):\n",
    "    t = threading.Thread(target=worker, args=(i,))\n",
    "    threads.append(t)\n",
    "    t.start()\n",
    "\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "# Con concurrent.futures (menos boilerplate)\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def worker(num):\n",
    "    print(f\"Tarea {num} completada\")\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    executor.map(worker, range(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios para Estudiantes\n",
    "\n",
    "1. **Descarga de páginas web concurrente**: \n",
    "   Implementa un script que descargue el contenido de múltiples URLs utilizando `ThreadPoolExecutor`. Compara el tiempo de ejecución con una implementación secuencial.\n",
    "\n",
    "2. **Procesamiento de imágenes paralelo**:\n",
    "   Crea un programa que aplique un filtro (por ejemplo, escala de grises) a un conjunto de imágenes utilizando `ProcessPoolExecutor`. Compara el rendimiento con diferentes números de workers.\n",
    "\n",
    "3. **Sistema de caché distribuido**:\n",
    "   Diseña un sistema simple de caché distribuido utilizando `ProcessPoolExecutor`, donde cada proceso maneja una parte de los datos en memoria.\n",
    "\n",
    "4. **Web scraping concurrente**:\n",
    "   Desarrolla un web scraper que extraiga información de múltiples páginas de un sitio web simultáneamente usando `ThreadPoolExecutor`.\n",
    "\n",
    "5. **Simulación de Monte Carlo paralela**:\n",
    "   Implementa una simulación de Monte Carlo (por ejemplo, para calcular π) utilizando `ProcessPoolExecutor` y compara la precisión y el tiempo de ejecución con diferentes números de procesos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias y Recursos Adicionales\n",
    "\n",
    "- [Documentación oficial de concurrent.futures](https://docs.python.org/3/library/concurrent.futures.html)\n",
    "- [PEP 3148 -- futures - execute computations asynchronously](https://www.python.org/dev/peps/pep-3148/)\n",
    "\n",
    "Recursos en línea gratuitos:\n",
    "- [Python Threading Tutorial: Run Code Concurrently Using the Threading Module](https://www.toptal.com/python/beginners-guide-to-concurrency-and-parallelism-in-python)\n",
    "- [Parallel Processing in Python: A Practical Guide with Examples](https://www.machinelearningplus.com/python/parallel-processing-python/)\n",
    "- [Python Multithreading and Multiprocessing Tutorial](https://www.tutorialspoint.com/python/python_multithreading.htm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
