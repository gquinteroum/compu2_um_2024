{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d93d231b",
   "metadata": {},
   "source": [
    "\n",
    "# Computación Distribuida con Celery\n",
    "\n",
    "Este notebook tiene como objetivo proporcionar una guía completa para implementar computación distribuida utilizando **Celery** en Python. Se exploran conceptos teóricos y técnicos, así como ejemplos prácticos para que los alumnos comprendan y apliquen Celery en distintos escenarios.\n",
    "\n",
    "## Contenidos\n",
    "1. Introducción a Celery\n",
    "2. Conceptos Básicos de Celery\n",
    "3. Introducción a Redis y RabbitMQ\n",
    "4. Configuración de Celery con Redis\n",
    "5. Ejemplo 1: Procesamiento Distribuido de Imágenes\n",
    "6. Ejemplo 2: Análisis de Datos en Paralelo\n",
    "7. Conclusión\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3815b254",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Introducción a Celery\n",
    "\n",
    "**Celery** es una biblioteca de Python para manejar tareas en segundo plano, distribuir trabajos entre múltiples máquinas y programar trabajos periódicos. Es útil en escenarios donde se requiere ejecutar procesos asíncronos o distribuir tareas para maximizar el uso de los recursos del sistema.\n",
    "\n",
    "Celery se utiliza comúnmente en sistemas de **computación distribuida**, donde se necesita paralelizar el trabajo para mejorar el rendimiento y la eficiencia. Los principales componentes de Celery son:\n",
    "\n",
    "- **Tareas (Tasks)**: Funciones que se ejecutan en segundo plano.\n",
    "- **Workers**: Procesos que ejecutan las tareas en uno o varios nodos (máquinas).\n",
    "- **Broker**: Sistema de mensajería que distribuye las tareas a los workers (ej., Redis o RabbitMQ).\n",
    "- **Backend**: Almacena el estado y los resultados de las tareas ejecutadas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d07608c",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Conceptos Básicos de Celery\n",
    "\n",
    "Los elementos clave en el ecosistema de Celery son:\n",
    "\n",
    "1. **Task (Tarea)**: Es una función Python que se define para ejecutarse en segundo plano. Celery envía las tareas a través del broker y se ejecutan por los workers.\n",
    "2. **Worker**: Es un proceso que se ejecuta en segundo plano y espera tareas del broker. Un worker puede ejecutarse en una o varias máquinas, y Celery puede coordinar varios workers al mismo tiempo.\n",
    "3. **Broker**: Es un sistema de mensajería que se encarga de distribuir las tareas a los workers. Los brokers más utilizados son Redis y RabbitMQ.\n",
    "4. **Backend**: Es el sistema que almacena el estado y el resultado de las tareas. Puede ser el mismo sistema que el broker (por ejemplo, Redis) o uno distinto.\n",
    "\n",
    "A continuación, se introduce Redis y RabbitMQ, los dos brokers más comunes usados con Celery.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab91c336",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Introducción a Redis y RabbitMQ\n",
    "\n",
    "### Redis\n",
    "**Redis** (Remote Dictionary Server) es una base de datos en memoria de estructura de datos clave-valor de alta velocidad. Actúa como broker en Celery al proporcionar colas de mensajes para la distribución de tareas.\n",
    "\n",
    "Características clave de Redis:\n",
    "- **Alto Rendimiento**: Redis está optimizado para manejar grandes cantidades de datos en memoria, lo que lo hace extremadamente rápido.\n",
    "- **Simplicidad**: Configurar Redis es sencillo y tiene un API intuitiva.\n",
    "- **Persistencia Opcional**: Aunque es una base de datos en memoria, Redis permite persistir datos en disco de forma opcional.\n",
    "\n",
    "### RabbitMQ\n",
    "**RabbitMQ** es un broker de mensajes más avanzado basado en el protocolo AMQP (Advanced Message Queuing Protocol). RabbitMQ permite colas más complejas y configuraciones avanzadas para la distribución de mensajes.\n",
    "\n",
    "Características clave de RabbitMQ:\n",
    "- **Soporte de AMQP**: RabbitMQ permite colas y mensajes más complejos que Redis.\n",
    "- **Durabilidad y Persistencia**: Los mensajes pueden persistirse en disco, lo que lo hace adecuado para aplicaciones críticas.\n",
    "- **Interoperabilidad**: RabbitMQ es compatible con muchos lenguajes y frameworks, lo que facilita su integración en sistemas heterogéneos.\n",
    "\n",
    "En este notebook, se utilizará **Redis** como broker de ejemplo, dado su fácil configuración y rapidez.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5007f25",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Configuración de Celery con Redis\n",
    "\n",
    "Para usar Celery con Redis, es necesario instalar Redis y la biblioteca Celery en el entorno de Python.\n",
    "\n",
    "### Instalación\n",
    "- Instalar Celery:\n",
    "    ```bash\n",
    "    pip install celery\n",
    "    ```\n",
    "- Instalar Redis en el sistema operativo o utilizar una instancia en la nube.\n",
    "\n",
    "### Configuración Básica\n",
    "\n",
    "A continuación, se muestra un ejemplo simple de configuración de Celery utilizando Redis como broker.\n",
    "\n",
    "```python\n",
    "# tasks.py\n",
    "from celery import Celery\n",
    "\n",
    "# Configuración de la aplicación Celery\n",
    "app = Celery('tasks', broker='redis://localhost:6379/0', backend='redis://localhost:6379/0')\n",
    "\n",
    "@app.task\n",
    "def add(x, y):\n",
    "    return x + y\n",
    "```\n",
    "\n",
    "Para ejecutar el worker de Celery, se utiliza el siguiente comando:\n",
    "\n",
    "```bash\n",
    "celery -A tasks worker --loglevel=info\n",
    "```\n",
    "\n",
    "El worker comenzará a escuchar tareas que se envíen al broker Redis. Este ejemplo configura una tarea simple (`add`) que suma dos números.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ac2121",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Ejemplo 1: Procesamiento Distribuido de Imágenes\n",
    "\n",
    "En este ejemplo, se muestra cómo distribuir el procesamiento de imágenes utilizando Celery. Se dividirán las tareas de procesamiento de imágenes entre varios workers en diferentes máquinas.\n",
    "\n",
    "```python\n",
    "# tasks.py\n",
    "from celery import Celery\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Conexión a Redis como broker\n",
    "app = Celery('image_processing', broker='redis://<BROKER_IP>:6379/0', backend='redis://<BROKER_IP>:6379/0')\n",
    "\n",
    "@app.task\n",
    "def process_image(image_path):\n",
    "    # Abre y procesa la imagen\n",
    "    with Image.open(image_path) as img:\n",
    "        grayscale_image = img.convert('L')\n",
    "        processed_path = os.path.splitext(image_path)[0] + '_processed.jpg'\n",
    "        grayscale_image.save(processed_path)\n",
    "        return processed_path\n",
    "```\n",
    "\n",
    "El worker se ejecuta con el siguiente comando:\n",
    "\n",
    "```bash\n",
    "celery -A tasks worker --loglevel=info\n",
    "```\n",
    "\n",
    "Para enviar tareas al worker:\n",
    "\n",
    "```python\n",
    "# main.py\n",
    "from tasks import process_image\n",
    "\n",
    "image_files = ['/path/to/image1.jpg', '/path/to/image2.jpg', '/path/to/image3.jpg']\n",
    "\n",
    "for image in image_files:\n",
    "    result = process_image.delay(image)\n",
    "    print(f\"Tarea enviada para {image}. Resultado en: {result.get()}\")\n",
    "```\n",
    "\n",
    "### Explicación\n",
    "- **Distribución de Tareas**: Las imágenes se distribuyen entre los workers, permitiendo que múltiples nodos procesen imágenes en paralelo.\n",
    "- **Escalabilidad**: Se pueden agregar más workers para manejar grandes cantidades de imágenes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e26366",
   "metadata": {},
   "source": [
    "\n",
    "## 6. Ejemplo 2: Análisis de Datos en Paralelo\n",
    "\n",
    "Este ejemplo muestra cómo usar Celery para dividir el análisis de un archivo CSV grande en fragmentos, distribuyendo la carga entre varios workers.\n",
    "\n",
    "```python\n",
    "# tasks.py\n",
    "from celery import Celery\n",
    "import pandas as pd\n",
    "\n",
    "# Configuración de la aplicación Celery\n",
    "app = Celery('data_analysis', broker='redis://<BROKER_IP>:6379/0', backend='redis://<BROKER_IP>:6379/0')\n",
    "\n",
    "@app.task\n",
    "def analyze_chunk(data_chunk):\n",
    "    # Convertimos el chunk en un DataFrame\n",
    "    df = pd.DataFrame(data_chunk)\n",
    "    \n",
    "    # Calcula estadísticas por categoría\n",
    "    total_per_category = df.groupby('category')['amount'].sum().to_dict()\n",
    "    average_per_category = df.groupby('category')['amount'].mean().to_dict()\n",
    "    \n",
    "    # Retorna los resultados como diccionarios\n",
    "    return {'total': total_per_category, 'average': average_per_category}\n",
    "```\n",
    "\n",
    "En este caso, la función `analyze_chunk` procesa un fragmento de datos del CSV, calculando el total y el promedio por categoría.\n",
    "\n",
    "### Distribuir las Tareas\n",
    "\n",
    "```python\n",
    "# main.py\n",
    "import pandas as pd\n",
    "from tasks import analyze_chunk\n",
    "\n",
    "# Ruta del archivo CSV\n",
    "file_path = 'large_transactions.csv'\n",
    "chunksize = 10000  # Cantidad de registros por fragmento\n",
    "\n",
    "results = []\n",
    "for chunk in pd.read_csv(file_path, chunksize=chunksize):\n",
    "    # Convertimos el DataFrame en un diccionario para enviarlo como tarea\n",
    "    data_chunk = chunk.to_dict(orient='records')\n",
    "    # Enviamos la tarea para que sea procesada por Celery\n",
    "    result = analyze_chunk.delay(data_chunk)\n",
    "    results.append(result)\n",
    "\n",
    "# Recopila los resultados cuando todas las tareas han terminado\n",
    "totals = {}\n",
    "averages = {}\n",
    "for result in results:\n",
    "    chunk_result = result.get()  # Espera a que cada tarea termine\n",
    "    for category, total in chunk_result['total'].items():\n",
    "        totals[category] = totals.get(category, 0) + total\n",
    "    for category, average in chunk_result['average'].items():\n",
    "        averages[category] = averages.get(category, 0) + average\n",
    "\n",
    "# Calcula el promedio global por categoría basado en el total y la cantidad de fragmentos\n",
    "for category in averages:\n",
    "    averages[category] /= len(results)\n",
    "\n",
    "print(\"Totales por categoría:\", totals)\n",
    "print(\"Promedios por categoría:\", averages)\n",
    "```\n",
    "\n",
    "### Explicación del Ejemplo\n",
    "- **Fragmentación del Archivo**: El archivo CSV se divide en fragmentos (chunks) manejables para evitar cargar todo el archivo en memoria.\n",
    "- **Distribución de Tareas**: Cada fragmento se envía como una tarea a Celery, y los workers lo procesan en paralelo.\n",
    "- **Recopilación de Resultados**: Los resultados de cada tarea se recopilan y consolidan para obtener totales y promedios globales.\n",
    "\n",
    "Este enfoque permite procesar archivos de gran tamaño de manera eficiente, aprovechando los recursos de múltiples máquinas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c09761",
   "metadata": {},
   "source": [
    "\n",
    "## 7. Conclusión\n",
    "\n",
    "Celery es una herramienta poderosa para la computación distribuida en Python, especialmente cuando se requiere manejar tareas asíncronas o distribuir cargas de trabajo de manera eficiente en múltiples nodos. Los ejemplos presentados demuestran cómo se puede aplicar Celery en distintos contextos:\n",
    "\n",
    "- **Procesamiento de Imágenes en Paralelo**: Utilizando Celery para distribuir tareas de procesamiento de imágenes, se puede aprovechar al máximo los recursos de múltiples máquinas.\n",
    "- **Análisis de Datos en Paralelo**: Dividiendo archivos CSV grandes en fragmentos y distribuyendo su procesamiento, Celery permite realizar cálculos complejos sin cargar en memoria grandes volúmenes de datos.\n",
    "\n",
    "### Puntos Clave\n",
    "- Celery se apoya en brokers como Redis o RabbitMQ para gestionar la distribución de tareas.\n",
    "- La escalabilidad horizontal es un beneficio clave, ya que se pueden agregar o quitar workers según la carga de trabajo.\n",
    "- El manejo eficiente de recursos y la posibilidad de persistencia de resultados hacen de Celery una opción robusta para sistemas distribuidos.\n",
    "\n",
    "El conocimiento de los fundamentos de Celery, junto con la comprensión de sus componentes y su configuración con diferentes brokers, es esencial para su uso efectivo en la práctica de la computación distribuida.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4244097",
   "metadata": {},
   "source": [
    "\n",
    "## 8. Computación Distribuida con Celery: Perspectiva Técnica\n",
    "\n",
    "Para entender cómo Celery maneja la computación distribuida, es importante analizar cómo se ejecutan y coordinan las tareas en el nivel del sistema operativo y cómo interactúan los distintos componentes.\n",
    "\n",
    "### 8.1 Manejo de Procesos y Threads\n",
    "\n",
    "Celery utiliza **procesos** y **threads** para gestionar las tareas en segundo plano:\n",
    "\n",
    "1. **Procesos**: Cuando se inicia un worker en Celery, este se ejecuta como un proceso del usuario en el sistema operativo. El worker puede manejar múltiples tareas a la vez, y dependiendo de la configuración, puede usar multiprocesamiento o multithreading.\n",
    "   - El kernel asigna tiempo de CPU a estos procesos basándose en la política de planificación del sistema operativo (por ejemplo, Round Robin o FIFO).\n",
    "   - Los procesos de Celery son gestionados por el kernel como cualquier otro proceso del espacio de usuario.\n",
    "\n",
    "2. **Threads**: Celery puede emplear threads dentro de los procesos para paralelizar aún más el trabajo. Los threads comparten memoria y recursos del proceso, lo que permite un acceso rápido, pero deben sincronizarse para evitar condiciones de carrera.\n",
    "   - El kernel gestiona estos threads a través de mecanismos de planificación y sincronización para maximizar el uso de la CPU y minimizar conflictos.\n",
    "\n",
    "### 8.2 Gestión de Memoria\n",
    "\n",
    "Celery opera en el **espacio de usuario** y, por tanto, depende del kernel para la gestión de la memoria:\n",
    "\n",
    "- **Asignación de Memoria**: Celery utiliza memoria para almacenar las tareas, sus resultados y el estado de los workers. El kernel asigna memoria virtual a los procesos de Celery y controla su acceso y paginación en caso de falta de memoria.\n",
    "- **Comunicación entre Threads y Procesos**: Para coordinar tareas y datos, Celery puede utilizar memoria compartida, un mecanismo facilitado por el kernel que permite que varios procesos accedan a una región de memoria común de manera controlada.\n",
    "\n",
    "### 8.3 Comunicación entre Procesos (IPC) y Brokers de Mensajería\n",
    "\n",
    "Celery se apoya en sistemas de mensajería como **Redis** y **RabbitMQ** para distribuir tareas entre nodos (máquinas). Estos sistemas usan sockets y otros mecanismos de IPC proporcionados por el kernel:\n",
    "\n",
    "- **Sockets**: Los workers se conectan al broker (Redis o RabbitMQ) mediante **sockets TCP/IP**. El kernel asigna puertos y buffers para gestionar estas conexiones, asegurando que los mensajes (tareas) se envíen y reciban correctamente.\n",
    "- **Inter-Process Communication (IPC)**: Celery utiliza mecanismos de IPC para sincronizar y comunicar procesos en una misma máquina o en una red distribuida. Esto permite la transmisión de datos y señales entre workers y el broker de manera eficiente.\n",
    "\n",
    "### 8.4 Coordinación de Múltiples Nodos\n",
    "\n",
    "Cuando Celery se configura en un entorno distribuido, los procesos y threads se extienden a través de múltiples nodos:\n",
    "\n",
    "- **Escalabilidad Horizontal**: Celery permite agregar y quitar nodos de forma dinámica. El kernel de cada nodo administra los procesos y threads, y Redis o RabbitMQ aseguran que las tareas se asignen a los nodos disponibles.\n",
    "- **Manejo de Fallos**: Si un nodo falla, Redis o RabbitMQ pueden reasignar las tareas pendientes a otros workers activos, utilizando características de persistencia y reintentos.\n",
    "- **Conexión en Red**: La red y el kernel juegan un papel crucial en la comunicación entre nodos. El broker (Redis o RabbitMQ) utiliza puertos y conexiones gestionadas por el kernel para coordinar los mensajes entre máquinas. Esto permite una baja latencia en la distribución de tareas.\n",
    "\n",
    "### 8.5 Señales del Sistema y Eventos\n",
    "\n",
    "Celery interactúa con el sistema operativo mediante **señales** y **eventos**:\n",
    "\n",
    "- **Señales**: Celery puede manejar señales del sistema operativo (como SIGTERM o SIGKILL) para iniciar, detener o reiniciar workers. Estas señales son gestionadas por el kernel y permiten una interacción directa con los procesos de Celery.\n",
    "- **Timers y Eventos**: Celery utiliza temporizadores y eventos para programar trabajos periódicos (a través de Celery Beat). El kernel proporciona mecanismos de temporización que Celery aprovecha para ejecutar tareas en momentos específicos.\n",
    "\n",
    "### Resumen\n",
    "\n",
    "Desde una perspectiva técnica, Celery es una aplicación de computación distribuida que se basa en el sistema operativo y sus servicios para coordinar y ejecutar tareas en segundo plano. La interacción con el kernel, la gestión de procesos y threads, y el uso de sistemas de mensajería como Redis y RabbitMQ son elementos fundamentales que permiten que Celery distribuya tareas eficientemente en múltiples nodos.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
